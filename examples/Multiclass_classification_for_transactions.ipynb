{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트랜잭션에 대한 다중 클래스 분류\n",
    "\n",
    "이 노트북에서는 트랜잭션의 공개 데이터 세트를 미리 정의한 여러 범주로 분류하려고 합니다. 이러한 접근 방식은 트랜잭션 데이터를 미리 정의된 범주에 맞추려는 모든 다중 클래스 분류 사용 사례에 복제할 수 있어야 하며, 이 과정을 마치면 레이블이 있는 데이터 세트와 레이블이 없는 데이터 세트를 모두 처리할 수 있는 몇 가지 접근 방식을 알게 될 것입니다.\n",
    "\n",
    "이 노트북에서 다룰 다양한 접근 방식은 다음과 같습니다:\n",
    "- **제로 샷 분류:** 먼저 안내 프롬프트만 사용하여 5개의 명명된 버킷 중 하나에 트랜잭션을 넣는 제로 샷 분류를 해보겠습니다.\n",
    "- **임베딩을 사용한 분류:** 그 다음에는 레이블이 지정된 데이터 세트에 임베딩을 생성한 다음, 전통적인 분류 모델을 사용해 카테고리를 식별하는 데 있어 임베딩이 얼마나 효과적인지 테스트합니다.\n",
    "- **미세 조정된 분류:** 마지막으로 라벨이 지정된 데이터 세트에 대해 학습된 미세 조정된 모델을 생성하여 제로 샷 및 소수 샷 분류 접근 방식과 비교합니다.\n",
    "\n",
    "-------------------\n",
    "\n",
    "For this notebook we will be looking to classify a public dataset of transactions into a number of categories that we have predefined. These approaches should be replicable to any multiclass classificaiton use case where we are trying to fit transactional data into predefined categories, and by the end of running through this you should have a few approaches for dealing with both labelled and unlabelled datasets.\n",
    "\n",
    "The different approaches we'll be taking in this notebook are:\n",
    "- **Zero-shot Classification:** First we'll do zero shot classification to put transactions in one of five named buckets using only a prompt for guidance\n",
    "- **Classification with Embeddings:** Following this we'll create embeddings on a labelled dataset, and then use a traditional classification model to test their effectiveness at identifying our categories\n",
    "- **Fine-tuned Classification:** Lastly we'll produce a fine-tuned model trained on our labelled dataset to see how this compares to the zero-shot and few-shot classification approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "COMPLETIONS_MODEL = \"text-davinci-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 집합 로드\n",
    "\n",
    "스코틀랜드 도서관에서 25,000파운드 이상의 공공 거래 데이터 집합을 사용하고 있습니다. 이 데이터 집합에는 세 가지 기능이 있습니다:\n",
    "- 공급업체: 공급업체의 이름\n",
    "- 설명: 거래에 대한 텍스트 설명\n",
    "- Value: GBP로 표시된 거래 금액\n",
    "\n",
    "**출처**:\n",
    "\n",
    "https://data.nls.uk/data/organisational-data/transactions-over-25k/\n",
    "\n",
    "-----------\n",
    "\n",
    "We're using a public transaction dataset of transactions over £25k for the Library of Scotland. The dataset has three features that we'll be using:\n",
    "- Supplier: The name of the supplier\n",
    "- Description: A text description of the transaction\n",
    "- Value: The value of the transaction in GBP\n",
    "\n",
    "**Source**:\n",
    "\n",
    "https://data.nls.uk/data/organisational-data/transactions-over-25k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = pd.read_csv('./data/25000_spend_dataset_current.csv', encoding= 'unicode_escape')\n",
    "len(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Description</th>\n",
       "      <th>Transaction value (£)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21/04/2016</td>\n",
       "      <td>M &amp; J Ballantyne Ltd</td>\n",
       "      <td>George IV Bridge Work</td>\n",
       "      <td>35098.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/04/2016</td>\n",
       "      <td>Private Sale</td>\n",
       "      <td>Literary &amp; Archival Items</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30/04/2016</td>\n",
       "      <td>City Of Edinburgh Council</td>\n",
       "      <td>Non Domestic Rates</td>\n",
       "      <td>40800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/05/2016</td>\n",
       "      <td>Computacenter Uk</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>72835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/05/2016</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>64361.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                      Supplier                 Description  \\\n",
       "0  21/04/2016          M & J Ballantyne Ltd       George IV Bridge Work   \n",
       "1  26/04/2016                  Private Sale   Literary & Archival Items   \n",
       "2  30/04/2016     City Of Edinburgh Council         Non Domestic Rates    \n",
       "3  09/05/2016              Computacenter Uk                 Kelvin Hall   \n",
       "4  09/05/2016  John Graham Construction Ltd  Causewayside Refurbishment   \n",
       "\n",
       "   Transaction value (£)  \n",
       "0                35098.0  \n",
       "1                30000.0  \n",
       "2                40800.0  \n",
       "3                72835.0  \n",
       "4                64361.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_completion(prompt):\n",
    "    \n",
    "    completion_response =   openai.Completion.create(\n",
    "                            prompt=prompt,\n",
    "                            temperature=0,\n",
    "                            max_tokens=5,\n",
    "                            top_p=1,\n",
    "                            frequency_penalty=0,\n",
    "                            presence_penalty=0,\n",
    "                            model=COMPLETIONS_MODEL\n",
    "                            )\n",
    "        \n",
    "    return completion_response\n",
    "\n",
    "def classify_transaction(transaction,prompt):\n",
    "    \n",
    "    prompt = prompt.replace('SUPPLIER_NAME',transaction['Supplier'])\n",
    "    prompt = prompt.replace('DESCRIPTION_TEXT',transaction['Description'])\n",
    "    prompt = prompt.replace('TRANSACTION_VALUE',str(transaction['Transaction value (£)']))\n",
    "    \n",
    "    classification = request_completion(prompt)['choices'][0]['text'].replace('\\n','')\n",
    "    \n",
    "    return classification\n",
    "\n",
    "# 이 함수는 Finetuning API의 prepare_data 함수에서 트레이닝 및 검증 출력을 가져와 다음과 같이 확인합니다.\n",
    "# 각각 동일한 수의 클래스가 있는지 확인합니다.\n",
    "# 클래스 수가 같지 않으면 미세 조정이 실패하고 오류를 반환합니다.\n",
    "\n",
    "# This function takes your training and validation outputs from the prepare_data function of the Finetuning API, and\n",
    "# confirms that each have the same number of classes.\n",
    "# If they do not have the same number of classes the fine-tune will fail and return an error\n",
    "\n",
    "def check_finetune_classes(train_file,valid_file):\n",
    "\n",
    "    train_classes = set()\n",
    "    valid_classes = set()\n",
    "    with open(train_file, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "        print(len(json_list))\n",
    "\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        train_classes.add(result['completion'])\n",
    "        #print(f\"result: {result['completion']}\")\n",
    "        #print(isinstance(result, dict))\n",
    "\n",
    "    with open(valid_file, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "        print(len(json_list))\n",
    "\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        valid_classes.add(result['completion'])\n",
    "        #print(f\"result: {result['completion']}\")\n",
    "        #print(isinstance(result, dict))\n",
    "        \n",
    "    if len(train_classes) == len(valid_classes):\n",
    "        print('All good')\n",
    "        \n",
    "    else:\n",
    "        print('Classes do not match, please prepare data again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제로 샷 분류\n",
    "\n",
    "먼저 간단한 프롬프트를 사용하여 이러한 트랜잭션을 분류하는 기본 모델의 성능을 평가해 보겠습니다. 모델에 5개의 카테고리를 제공하고 분류할 수 없는 카테고리에 대해서는 '분류할 수 없음'이라는 포괄적인 항목을 표시합니다.\n",
    "\n",
    "---------------------\n",
    "\n",
    "We'll first assess the performance of the base models at classifying these transactions using a simple prompt. We'll provide the model with 5 categories and a catch-all of \"Could not classify\" for ones that it cannot place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = '''You are a data expert working for the National Library of Scotland. \n",
    "You are analysing all transactions over £25,000 in value and classifying them into one of five categories.\n",
    "The five categories are Building Improvement, Literature & Archive, Utility Bills, Professional Services and Software/IT.\n",
    "If you can't tell what it is, say Could not classify\n",
    "                      \n",
    "Transaction:\n",
    "                      \n",
    "Supplier: SUPPLIER_NAME\n",
    "Description: DESCRIPTION_TEXT\n",
    "Value: TRANSACTION_VALUE\n",
    "                      \n",
    "The classification is:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Building Improvement\n"
     ]
    }
   ],
   "source": [
    "# Get a test transaction\n",
    "transaction = transactions.iloc[0]\n",
    "\n",
    "# Interpolate the values into the prompt\n",
    "prompt = zero_shot_prompt.replace('SUPPLIER_NAME',transaction['Supplier'])\n",
    "prompt = prompt.replace('DESCRIPTION_TEXT',transaction['Description'])\n",
    "prompt = prompt.replace('TRANSACTION_VALUE',str(transaction['Transaction value (£)']))\n",
    "\n",
    "# Use our completion function to return a prediction\n",
    "completion_response = request_completion(prompt)\n",
    "print(completion_response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 시도는 정확합니다. M & J Ballantyne Ltd는 주택 건설업체이며 그들이 수행한 작업은 실제로 건물 개선입니다.\n",
    "\n",
    "샘플 크기를 25개로 확장하고 간단한 안내 메시지를 통해 다시 한 번 성능을 확인해 보겠습니다.\n",
    "\n",
    "-----------\n",
    "\n",
    "Our first attempt is correct, M & J Ballantyne Ltd are a house builder and the work they performed is indeed Building Improvement.\n",
    "\n",
    "Lets expand the sample size to 25 and see how it performs, again with just a simple prompt to guide it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/sb5t91f56gj1dn_s_jvb37cc0000gn/T/ipykernel_12045/2849801388.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_transactions['Classification'] = test_transactions.apply(lambda x: classify_transaction(x,zero_shot_prompt),axis=1)\n"
     ]
    }
   ],
   "source": [
    "test_transactions = transactions.iloc[:25]\n",
    "test_transactions['Classification'] = test_transactions.apply(lambda x: classify_transaction(x,zero_shot_prompt),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Building Improvement     10\n",
       " Professional Services     8\n",
       " Software/IT               4\n",
       " Literature & Archive      3\n",
       "Name: Classification, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transactions['Classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Description</th>\n",
       "      <th>Transaction value (£)</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21/04/2016</td>\n",
       "      <td>M &amp; J Ballantyne Ltd</td>\n",
       "      <td>George IV Bridge Work</td>\n",
       "      <td>35098.0</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26/04/2016</td>\n",
       "      <td>Private Sale</td>\n",
       "      <td>Literary &amp; Archival Items</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Literature &amp; Archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30/04/2016</td>\n",
       "      <td>City Of Edinburgh Council</td>\n",
       "      <td>Non Domestic Rates</td>\n",
       "      <td>40800.0</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09/05/2016</td>\n",
       "      <td>Computacenter Uk</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>72835.0</td>\n",
       "      <td>Software/IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/05/2016</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>64361.0</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09/05/2016</td>\n",
       "      <td>A McGillivray</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>53690.0</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16/05/2016</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>365344.0</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23/05/2016</td>\n",
       "      <td>Computacenter Uk</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>26506.0</td>\n",
       "      <td>Software/IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23/05/2016</td>\n",
       "      <td>ECG Facilities Service</td>\n",
       "      <td>Facilities Management Charge</td>\n",
       "      <td>32777.0</td>\n",
       "      <td>Professional Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23/05/2016</td>\n",
       "      <td>ECG Facilities Service</td>\n",
       "      <td>Facilities Management Charge</td>\n",
       "      <td>32777.0</td>\n",
       "      <td>Professional Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30/05/2016</td>\n",
       "      <td>ALDL</td>\n",
       "      <td>ALDL Charges</td>\n",
       "      <td>32317.0</td>\n",
       "      <td>Professional Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10/06/2016</td>\n",
       "      <td>Wavetek Ltd</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>87589.0</td>\n",
       "      <td>Software/IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10/06/2016</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>381803.0</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28/06/2016</td>\n",
       "      <td>ECG Facilities Service</td>\n",
       "      <td>Facilities Management Charge</td>\n",
       "      <td>32832.0</td>\n",
       "      <td>Professional Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30/06/2016</td>\n",
       "      <td>Glasgow City Council</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11/07/2016</td>\n",
       "      <td>Wavetek Ltd</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>65692.0</td>\n",
       "      <td>Software/IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11/07/2016</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>139845.0</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15/07/2016</td>\n",
       "      <td>Sotheby'S</td>\n",
       "      <td>Literary &amp; Archival Items</td>\n",
       "      <td>28500.0</td>\n",
       "      <td>Literature &amp; Archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18/07/2016</td>\n",
       "      <td>Christies</td>\n",
       "      <td>Literary &amp; Archival Items</td>\n",
       "      <td>33800.0</td>\n",
       "      <td>Literature &amp; Archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25/07/2016</td>\n",
       "      <td>A McGillivray</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>30113.0</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31/07/2016</td>\n",
       "      <td>ALDL</td>\n",
       "      <td>ALDL Charges</td>\n",
       "      <td>32317.0</td>\n",
       "      <td>Professional Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>08/08/2016</td>\n",
       "      <td>ECG Facilities Service</td>\n",
       "      <td>Facilities Management Charge</td>\n",
       "      <td>32795.0</td>\n",
       "      <td>Professional Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15/08/2016</td>\n",
       "      <td>Creative Video Productions Ltd</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>26866.0</td>\n",
       "      <td>Professional Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15/08/2016</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>196807.0</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24/08/2016</td>\n",
       "      <td>ECG Facilities Service</td>\n",
       "      <td>Facilities Management Charge</td>\n",
       "      <td>32795.0</td>\n",
       "      <td>Professional Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                        Supplier                   Description  \\\n",
       "0   21/04/2016            M & J Ballantyne Ltd         George IV Bridge Work   \n",
       "1   26/04/2016                    Private Sale     Literary & Archival Items   \n",
       "2   30/04/2016       City Of Edinburgh Council           Non Domestic Rates    \n",
       "3   09/05/2016                Computacenter Uk                   Kelvin Hall   \n",
       "4   09/05/2016    John Graham Construction Ltd    Causewayside Refurbishment   \n",
       "5   09/05/2016                   A McGillivray    Causewayside Refurbishment   \n",
       "6   16/05/2016    John Graham Construction Ltd    Causewayside Refurbishment   \n",
       "7   23/05/2016                Computacenter Uk                   Kelvin Hall   \n",
       "8   23/05/2016          ECG Facilities Service  Facilities Management Charge   \n",
       "9   23/05/2016          ECG Facilities Service  Facilities Management Charge   \n",
       "10  30/05/2016                            ALDL                  ALDL Charges   \n",
       "11  10/06/2016                     Wavetek Ltd                   Kelvin Hall   \n",
       "12  10/06/2016    John Graham Construction Ltd    Causewayside Refurbishment   \n",
       "13  28/06/2016          ECG Facilities Service  Facilities Management Charge   \n",
       "14  30/06/2016            Glasgow City Council                   Kelvin Hall   \n",
       "15  11/07/2016                     Wavetek Ltd                   Kelvin Hall   \n",
       "16  11/07/2016    John Graham Construction Ltd    Causewayside Refurbishment   \n",
       "17  15/07/2016                       Sotheby'S     Literary & Archival Items   \n",
       "18  18/07/2016                       Christies     Literary & Archival Items   \n",
       "19  25/07/2016                   A McGillivray    Causewayside Refurbishment   \n",
       "20  31/07/2016                            ALDL                  ALDL Charges   \n",
       "21  08/08/2016          ECG Facilities Service  Facilities Management Charge   \n",
       "22  15/08/2016  Creative Video Productions Ltd                   Kelvin Hall   \n",
       "23  15/08/2016    John Graham Construction Ltd    Causewayside Refurbishment   \n",
       "24  24/08/2016          ECG Facilities Service  Facilities Management Charge   \n",
       "\n",
       "    Transaction value (£)          Classification  \n",
       "0                 35098.0    Building Improvement  \n",
       "1                 30000.0    Literature & Archive  \n",
       "2                 40800.0    Building Improvement  \n",
       "3                 72835.0             Software/IT  \n",
       "4                 64361.0    Building Improvement  \n",
       "5                 53690.0    Building Improvement  \n",
       "6                365344.0    Building Improvement  \n",
       "7                 26506.0             Software/IT  \n",
       "8                 32777.0   Professional Services  \n",
       "9                 32777.0   Professional Services  \n",
       "10                32317.0   Professional Services  \n",
       "11                87589.0             Software/IT  \n",
       "12               381803.0    Building Improvement  \n",
       "13                32832.0   Professional Services  \n",
       "14              1700000.0    Building Improvement  \n",
       "15                65692.0             Software/IT  \n",
       "16               139845.0    Building Improvement  \n",
       "17                28500.0    Literature & Archive  \n",
       "18                33800.0    Literature & Archive  \n",
       "19                30113.0    Building Improvement  \n",
       "20                32317.0   Professional Services  \n",
       "21                32795.0   Professional Services  \n",
       "22                26866.0   Professional Services  \n",
       "23               196807.0    Building Improvement  \n",
       "24                32795.0   Professional Services  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transactions.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블이 지정된 예가 없어도 초기 결과는 꽤 괜찮습니다! 분류할 수 없었던 사례들은 주제에 대한 단서가 거의 없는 어려운 사례들이었지만, 레이블이 지정된 데이터 세트를 정리하여 더 많은 예제를 제공하면 더 나은 성능을 얻을 수 있을 것입니다.\n",
    "\n",
    "------------------------------\n",
    "\n",
    "Initial results are pretty good even with no labelled examples! The ones that it could not classify were tougher cases with few clues as to their topic, but maybe if we clean up the labelled dataset to give more examples we can get better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임베딩을 사용한 분류\n",
    "\n",
    "지금까지 분류한 작은 세트에서 임베딩을 생성해 보겠습니다. 데이터 세트의 101개 트랜잭션에 대해 제로 샷 분류기를 실행하고 15개의 **분류할 수 없음** 결과를 수동으로 수정하여 레이블이 지정된 예제 세트를 만들었습니다.\n",
    "\n",
    "---------------\n",
    "\n",
    "Lets create embeddings from the small set that we've classified so far - we've made a set of labelled examples by running the zero-shot classifier on 101 transactions from our dataset and manually correcting the 15 **Could not classify** results that we got\n",
    "\n",
    "### 임베딩 생성\n",
    "\n",
    "이 초기 섹션에서는 모든 기능을 연결하는 결합된 필드에서 임베딩을 생성하기 위해 [데이터 세트 가져오기 노트북](Obtain_dataset.ipynb)의 접근 방식을 재사용합니다.\n",
    "\n",
    "---------------\n",
    "\n",
    "This initial section reuses the approach from the [Obtain_dataset Notebook](Obtain_dataset.ipynb) to create embeddings from a combined field concatenating all of our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Description</th>\n",
       "      <th>Transaction value (£)</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/08/2016</td>\n",
       "      <td>Creative Video Productions Ltd</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>26866</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29/05/2017</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>74806</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29/05/2017</td>\n",
       "      <td>Morris &amp; Spottiswood Ltd</td>\n",
       "      <td>George IV Bridge Work</td>\n",
       "      <td>56448</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31/05/2017</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>164691</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24/07/2017</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>27926</td>\n",
       "      <td>Building Improvement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                        Supplier                 Description  \\\n",
       "0  15/08/2016  Creative Video Productions Ltd                 Kelvin Hall   \n",
       "1  29/05/2017    John Graham Construction Ltd  Causewayside Refurbishment   \n",
       "2  29/05/2017        Morris & Spottiswood Ltd       George IV Bridge Work   \n",
       "3  31/05/2017    John Graham Construction Ltd  Causewayside Refurbishment   \n",
       "4  24/07/2017    John Graham Construction Ltd  Causewayside Refurbishment   \n",
       "\n",
       "   Transaction value (£)        Classification  \n",
       "0                  26866                 Other  \n",
       "1                  74806  Building Improvement  \n",
       "2                  56448  Building Improvement  \n",
       "3                 164691  Building Improvement  \n",
       "4                  27926  Building Improvement  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/labelled_transactions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Description</th>\n",
       "      <th>Transaction value (£)</th>\n",
       "      <th>Classification</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/08/2016</td>\n",
       "      <td>Creative Video Productions Ltd</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>26866</td>\n",
       "      <td>Other</td>\n",
       "      <td>Supplier: Creative Video Productions Ltd; Desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29/05/2017</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>74806</td>\n",
       "      <td>Building Improvement</td>\n",
       "      <td>Supplier: John Graham Construction Ltd; Descri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                        Supplier                 Description  \\\n",
       "0  15/08/2016  Creative Video Productions Ltd                 Kelvin Hall   \n",
       "1  29/05/2017    John Graham Construction Ltd  Causewayside Refurbishment   \n",
       "\n",
       "   Transaction value (£)        Classification  \\\n",
       "0                  26866                 Other   \n",
       "1                  74806  Building Improvement   \n",
       "\n",
       "                                            combined  \n",
       "0  Supplier: Creative Video Productions Ltd; Desc...  \n",
       "1  Supplier: John Graham Construction Ltd; Descri...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['combined'] = \"Supplier: \" + df['Supplier'].str.strip() + \"; Description: \" + df['Description'].str.strip() + \"; Value: \" + str(df['Transaction value (£)']).strip()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "df['n_tokens'] = df.combined.apply(lambda x: len(tokenizer.encode(x)))\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = './data/transactions_with_embeddings_100.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding\n",
    "\n",
    "df['babbage_similarity'] = df.combined.apply(lambda x: get_embedding(x, engine='text-similarity-babbage-001'))\n",
    "df['babbage_search'] = df.combined.apply(lambda x: get_embedding(x, engine='text-search-babbage-doc-001'))\n",
    "df.to_csv(embedding_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류에 임베딩 사용\n",
    "\n",
    "이제 임베딩을 만들었으니 이름을 지정한 카테고리로 분류했을 때 어떤 효과가 있는지 살펴봅시다.\n",
    "\n",
    "이를 위해 [Classification_using_embeddings](Classification_using_embeddings.ipynb) 노트북의 템플릿을 사용하겠습니다.\n",
    "\n",
    "-------------\n",
    "\n",
    "Now that we have our embeddings, let see if classifying these into the categories we've named gives us any more success.\n",
    "\n",
    "For this we'll use a template from the [Classification_using_embeddings](Classification_using_embeddings.ipynb) notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Description</th>\n",
       "      <th>Transaction value (£)</th>\n",
       "      <th>Classification</th>\n",
       "      <th>combined</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>babbage_similarity</th>\n",
       "      <th>babbage_search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15/08/2016</td>\n",
       "      <td>Creative Video Productions Ltd</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>26866</td>\n",
       "      <td>Other</td>\n",
       "      <td>Supplier: Creative Video Productions Ltd; Desc...</td>\n",
       "      <td>136</td>\n",
       "      <td>[-0.009802100248634815, 0.022551486268639565, ...</td>\n",
       "      <td>[-0.00232666521333158, 0.019198870286345482, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29/05/2017</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>74806</td>\n",
       "      <td>Building Improvement</td>\n",
       "      <td>Supplier: John Graham Construction Ltd; Descri...</td>\n",
       "      <td>140</td>\n",
       "      <td>[-0.009065819904208183, 0.012094118632376194, ...</td>\n",
       "      <td>[0.005169447045773268, 0.00473341578617692, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29/05/2017</td>\n",
       "      <td>Morris &amp; Spottiswood Ltd</td>\n",
       "      <td>George IV Bridge Work</td>\n",
       "      <td>56448</td>\n",
       "      <td>Building Improvement</td>\n",
       "      <td>Supplier: Morris &amp; Spottiswood Ltd; Descriptio...</td>\n",
       "      <td>141</td>\n",
       "      <td>[-0.009000026620924473, 0.02405017428100109, -...</td>\n",
       "      <td>[0.0028343256562948227, 0.021166473627090454, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31/05/2017</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>164691</td>\n",
       "      <td>Building Improvement</td>\n",
       "      <td>Supplier: John Graham Construction Ltd; Descri...</td>\n",
       "      <td>140</td>\n",
       "      <td>[-0.009065819904208183, 0.012094118632376194, ...</td>\n",
       "      <td>[0.005169447045773268, 0.00473341578617692, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24/07/2017</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>27926</td>\n",
       "      <td>Building Improvement</td>\n",
       "      <td>Supplier: John Graham Construction Ltd; Descri...</td>\n",
       "      <td>140</td>\n",
       "      <td>[-0.009065819904208183, 0.012094118632376194, ...</td>\n",
       "      <td>[0.005169447045773268, 0.00473341578617692, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                        Supplier  \\\n",
       "0           0  15/08/2016  Creative Video Productions Ltd   \n",
       "1           1  29/05/2017    John Graham Construction Ltd   \n",
       "2           2  29/05/2017        Morris & Spottiswood Ltd   \n",
       "3           3  31/05/2017    John Graham Construction Ltd   \n",
       "4           4  24/07/2017    John Graham Construction Ltd   \n",
       "\n",
       "                  Description  Transaction value (£)        Classification  \\\n",
       "0                 Kelvin Hall                  26866                 Other   \n",
       "1  Causewayside Refurbishment                  74806  Building Improvement   \n",
       "2       George IV Bridge Work                  56448  Building Improvement   \n",
       "3  Causewayside Refurbishment                 164691  Building Improvement   \n",
       "4  Causewayside Refurbishment                  27926  Building Improvement   \n",
       "\n",
       "                                            combined  n_tokens  \\\n",
       "0  Supplier: Creative Video Productions Ltd; Desc...       136   \n",
       "1  Supplier: John Graham Construction Ltd; Descri...       140   \n",
       "2  Supplier: Morris & Spottiswood Ltd; Descriptio...       141   \n",
       "3  Supplier: John Graham Construction Ltd; Descri...       140   \n",
       "4  Supplier: John Graham Construction Ltd; Descri...       140   \n",
       "\n",
       "                                  babbage_similarity  \\\n",
       "0  [-0.009802100248634815, 0.022551486268639565, ...   \n",
       "1  [-0.009065819904208183, 0.012094118632376194, ...   \n",
       "2  [-0.009000026620924473, 0.02405017428100109, -...   \n",
       "3  [-0.009065819904208183, 0.012094118632376194, ...   \n",
       "4  [-0.009065819904208183, 0.012094118632376194, ...   \n",
       "\n",
       "                                      babbage_search  \n",
       "0  [-0.00232666521333158, 0.019198870286345482, 0...  \n",
       "1  [0.005169447045773268, 0.00473341578617692, -0...  \n",
       "2  [0.0028343256562948227, 0.021166473627090454, ...  \n",
       "3  [0.005169447045773268, 0.00473341578617692, -0...  \n",
       "4  [0.005169447045773268, 0.00473341578617692, -0...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "fs_df = pd.read_csv(embedding_path)\n",
    "fs_df[\"babbage_similarity\"] = fs_df.babbage_similarity.apply(eval).apply(np.array)\n",
    "fs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Building Improvement       0.92      1.00      0.96        11\n",
      "Literature & Archive       1.00      1.00      1.00         3\n",
      "               Other       0.00      0.00      0.00         1\n",
      "         Software/IT       1.00      1.00      1.00         1\n",
      "       Utility Bills       1.00      1.00      1.00         5\n",
      "\n",
      "            accuracy                           0.95        21\n",
      "           macro avg       0.78      0.80      0.79        21\n",
      "        weighted avg       0.91      0.95      0.93        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    list(fs_df.babbage_similarity.values), fs_df.Classification, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "probas = clf.predict_proba(X_test)\n",
    "\n",
    "report = classification_report(y_test, preds)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델의 성능은 매우 강력하므로 임베딩을 생성하고 더 간단한 분류기를 사용하는 것도 효과적인 접근 방식처럼 보이며, 제로 샷 분류기는 라벨이 없는 데이터 세트의 초기 분류를 수행하는 데 도움이 됩니다.\n",
    "\n",
    "한 걸음 더 나아가, 동일한 레이블이 지정된 데이터 세트에 대해 학습된 미세 조정된 모델이 비슷한 결과를 제공하는지 살펴봅시다.\n",
    "\n",
    "-----------------\n",
    "\n",
    "Performance for this model is pretty strong, so creating embeddings and using even a simpler classifier looks like an effective approach as well, with the zero-shot classifier helping us do the initial classification of the unlabelled dataset.\n",
    "\n",
    "Lets take it one step further and see if a fine-tuned model trained on this same labelled datasets gives us comparable results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 미세 조정된 트랜잭션 분류\n",
    "\n",
    "이 사용 사례에서는 동일한 레이블이 지정된 101개의 트랜잭션 집합에 대해 미세 조정된 모델을 학습하고 이 미세 조정된 모델을 보이지 않는 트랜잭션 그룹에 적용하여 위의 몇 가지 샷 분류를 개선해 보겠습니다.\n",
    "\n",
    "-------------------------------\n",
    "\n",
    "For this use case we're going to try to improve on the few-shot classification from above by training a fine-tuned model on the same labelled set of 101 transactions and applying this fine-tuned model on group of unseen transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미세 조정된 분류기 구축하기\n",
    "\n",
    "먼저 데이터를 준비하기 위해 몇 가지 데이터 준비 작업을 수행해야 합니다. 이 작업은 다음 단계를 거치게 됩니다:\n",
    "- 먼저 클래스를 나열하고 숫자 식별자로 대체합니다. '건물 개선'과 같이 여러 개의 연속된 토큰이 아닌 단일 토큰을 예측하도록 모델을 만들면 더 나은 결과를 얻을 수 있습니다.\n",
    "- 또한 각 예제에 공통 접두사와 접미사를 추가하여 모델이 예측할 수 있도록 지원해야 합니다. 이 경우 텍스트가 이미 'Supplier'로 시작하므로 접미사 '\\n\\n###\\n\\n'을 추가하겠습니다.\n",
    "- 마지막으로 분류를 위해 각 대상 클래스에 선행 공백을 추가하여 모델을 다시 한 번 지원합니다.\n",
    "\n",
    "--------------\n",
    "\n",
    "We'll need to do some data prep first to get our data ready. This will take the following steps:\n",
    "- First we'll list out our classes and replace them with numeric identifiers. Making the model predict a single token rather than multiple consecutive ones like 'Building Improvement' should give us better results\n",
    "- We also need to add a common prefix and suffix to each example to aid the model in making predictions - in our case our text is already started with 'Supplier' and we'll add a suffix of '\\n\\n###\\n\\n'\n",
    "- Lastly we'll aid a leading whitespace onto each of our target classes for classification, again to aid the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_prep_df = fs_df.copy()\n",
    "len(ft_prep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Description</th>\n",
       "      <th>Transaction value (£)</th>\n",
       "      <th>Classification</th>\n",
       "      <th>combined</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>babbage_similarity</th>\n",
       "      <th>babbage_search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15/08/2016</td>\n",
       "      <td>Creative Video Productions Ltd</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>26866</td>\n",
       "      <td>Other</td>\n",
       "      <td>Supplier: Creative Video Productions Ltd; Desc...</td>\n",
       "      <td>136</td>\n",
       "      <td>[-0.009802100248634815, 0.022551486268639565, ...</td>\n",
       "      <td>[-0.00232666521333158, 0.019198870286345482, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29/05/2017</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>74806</td>\n",
       "      <td>Building Improvement</td>\n",
       "      <td>Supplier: John Graham Construction Ltd; Descri...</td>\n",
       "      <td>140</td>\n",
       "      <td>[-0.009065819904208183, 0.012094118632376194, ...</td>\n",
       "      <td>[0.005169447045773268, 0.00473341578617692, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>29/05/2017</td>\n",
       "      <td>Morris &amp; Spottiswood Ltd</td>\n",
       "      <td>George IV Bridge Work</td>\n",
       "      <td>56448</td>\n",
       "      <td>Building Improvement</td>\n",
       "      <td>Supplier: Morris &amp; Spottiswood Ltd; Descriptio...</td>\n",
       "      <td>141</td>\n",
       "      <td>[-0.009000026620924473, 0.02405017428100109, -...</td>\n",
       "      <td>[0.0028343256562948227, 0.021166473627090454, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31/05/2017</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>164691</td>\n",
       "      <td>Building Improvement</td>\n",
       "      <td>Supplier: John Graham Construction Ltd; Descri...</td>\n",
       "      <td>140</td>\n",
       "      <td>[-0.009065819904208183, 0.012094118632376194, ...</td>\n",
       "      <td>[0.005169447045773268, 0.00473341578617692, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24/07/2017</td>\n",
       "      <td>John Graham Construction Ltd</td>\n",
       "      <td>Causewayside Refurbishment</td>\n",
       "      <td>27926</td>\n",
       "      <td>Building Improvement</td>\n",
       "      <td>Supplier: John Graham Construction Ltd; Descri...</td>\n",
       "      <td>140</td>\n",
       "      <td>[-0.009065819904208183, 0.012094118632376194, ...</td>\n",
       "      <td>[0.005169447045773268, 0.00473341578617692, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                        Supplier  \\\n",
       "0           0  15/08/2016  Creative Video Productions Ltd   \n",
       "1           1  29/05/2017    John Graham Construction Ltd   \n",
       "2           2  29/05/2017        Morris & Spottiswood Ltd   \n",
       "3           3  31/05/2017    John Graham Construction Ltd   \n",
       "4           4  24/07/2017    John Graham Construction Ltd   \n",
       "\n",
       "                  Description  Transaction value (£)        Classification  \\\n",
       "0                 Kelvin Hall                  26866                 Other   \n",
       "1  Causewayside Refurbishment                  74806  Building Improvement   \n",
       "2       George IV Bridge Work                  56448  Building Improvement   \n",
       "3  Causewayside Refurbishment                 164691  Building Improvement   \n",
       "4  Causewayside Refurbishment                  27926  Building Improvement   \n",
       "\n",
       "                                            combined  n_tokens  \\\n",
       "0  Supplier: Creative Video Productions Ltd; Desc...       136   \n",
       "1  Supplier: John Graham Construction Ltd; Descri...       140   \n",
       "2  Supplier: Morris & Spottiswood Ltd; Descriptio...       141   \n",
       "3  Supplier: John Graham Construction Ltd; Descri...       140   \n",
       "4  Supplier: John Graham Construction Ltd; Descri...       140   \n",
       "\n",
       "                                  babbage_similarity  \\\n",
       "0  [-0.009802100248634815, 0.022551486268639565, ...   \n",
       "1  [-0.009065819904208183, 0.012094118632376194, ...   \n",
       "2  [-0.009000026620924473, 0.02405017428100109, -...   \n",
       "3  [-0.009065819904208183, 0.012094118632376194, ...   \n",
       "4  [-0.009065819904208183, 0.012094118632376194, ...   \n",
       "\n",
       "                                      babbage_search  \n",
       "0  [-0.00232666521333158, 0.019198870286345482, 0...  \n",
       "1  [0.005169447045773268, 0.00473341578617692, -0...  \n",
       "2  [0.0028343256562948227, 0.021166473627090454, ...  \n",
       "3  [0.005169447045773268, 0.00473341578617692, -0...  \n",
       "4  [0.005169447045773268, 0.00473341578617692, -0...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_prep_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   class_id                 class\n",
       " 0         0                 Other\n",
       " 1         1  Building Improvement\n",
       " 2         2           Software/IT\n",
       " 3         3         Utility Bills\n",
       " 4         4  Literature & Archive,\n",
       " 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(set(ft_prep_df['Classification']))\n",
    "class_df = pd.DataFrame(classes).reset_index()\n",
    "class_df.columns = ['class_id','class']\n",
    "class_df  , len(class_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Description</th>\n",
       "      <th>Transaction value (£)</th>\n",
       "      <th>Classification</th>\n",
       "      <th>combined</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>babbage_similarity</th>\n",
       "      <th>babbage_search</th>\n",
       "      <th>class_id</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15/08/2016</td>\n",
       "      <td>Creative Video Productions Ltd</td>\n",
       "      <td>Kelvin Hall</td>\n",
       "      <td>26866</td>\n",
       "      <td>Other</td>\n",
       "      <td>Supplier: Creative Video Productions Ltd; Desc...</td>\n",
       "      <td>136</td>\n",
       "      <td>[-0.009802100248634815, 0.022551486268639565, ...</td>\n",
       "      <td>[-0.00232666521333158, 0.019198870286345482, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>Supplier: Creative Video Productions Ltd; Desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>31/03/2017</td>\n",
       "      <td>NLS Foundation</td>\n",
       "      <td>Grant Payment</td>\n",
       "      <td>177500</td>\n",
       "      <td>Other</td>\n",
       "      <td>Supplier: NLS Foundation; Description: Grant P...</td>\n",
       "      <td>135</td>\n",
       "      <td>[-0.015305811539292336, 0.022675275802612305, ...</td>\n",
       "      <td>[-0.006104097235947847, 0.020085038617253304, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Supplier: NLS Foundation; Description: Grant P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>26/06/2017</td>\n",
       "      <td>British Library</td>\n",
       "      <td>Legal Deposit Services</td>\n",
       "      <td>50056</td>\n",
       "      <td>Other</td>\n",
       "      <td>Supplier: British Library; Description: Legal ...</td>\n",
       "      <td>135</td>\n",
       "      <td>[-0.015445035882294178, 0.027791442349553108, ...</td>\n",
       "      <td>[-0.01456734724342823, 0.03029645048081875, -0...</td>\n",
       "      <td>0</td>\n",
       "      <td>Supplier: British Library; Description: Legal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>24/07/2017</td>\n",
       "      <td>ALDL</td>\n",
       "      <td>Legal Deposit Services</td>\n",
       "      <td>27067</td>\n",
       "      <td>Other</td>\n",
       "      <td>Supplier: ALDL; Description: Legal Deposit Ser...</td>\n",
       "      <td>135</td>\n",
       "      <td>[-0.011744093149900436, 0.01669803448021412, -...</td>\n",
       "      <td>[-0.008064398542046547, 0.012981051579117775, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Supplier: ALDL; Description: Legal Deposit Ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>24/07/2017</td>\n",
       "      <td>AM Phillip</td>\n",
       "      <td>Vehicle Purchase</td>\n",
       "      <td>26604</td>\n",
       "      <td>Other</td>\n",
       "      <td>Supplier: AM Phillip; Description: Vehicle Pur...</td>\n",
       "      <td>134</td>\n",
       "      <td>[-0.011187470518052578, 0.01638782024383545, -...</td>\n",
       "      <td>[0.003970459569245577, 0.013751459307968616, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>Supplier: AM Phillip; Description: Vehicle Pur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date                        Supplier  \\\n",
       "0           0  15/08/2016  Creative Video Productions Ltd   \n",
       "1          51  31/03/2017                  NLS Foundation   \n",
       "2          70  26/06/2017                 British Library   \n",
       "3          71  24/07/2017                            ALDL   \n",
       "4         100  24/07/2017                      AM Phillip   \n",
       "\n",
       "              Description  Transaction value (£) Classification  \\\n",
       "0             Kelvin Hall                  26866          Other   \n",
       "1           Grant Payment                 177500          Other   \n",
       "2  Legal Deposit Services                  50056          Other   \n",
       "3  Legal Deposit Services                  27067          Other   \n",
       "4        Vehicle Purchase                  26604          Other   \n",
       "\n",
       "                                            combined  n_tokens  \\\n",
       "0  Supplier: Creative Video Productions Ltd; Desc...       136   \n",
       "1  Supplier: NLS Foundation; Description: Grant P...       135   \n",
       "2  Supplier: British Library; Description: Legal ...       135   \n",
       "3  Supplier: ALDL; Description: Legal Deposit Ser...       135   \n",
       "4  Supplier: AM Phillip; Description: Vehicle Pur...       134   \n",
       "\n",
       "                                  babbage_similarity  \\\n",
       "0  [-0.009802100248634815, 0.022551486268639565, ...   \n",
       "1  [-0.015305811539292336, 0.022675275802612305, ...   \n",
       "2  [-0.015445035882294178, 0.027791442349553108, ...   \n",
       "3  [-0.011744093149900436, 0.01669803448021412, -...   \n",
       "4  [-0.011187470518052578, 0.01638782024383545, -...   \n",
       "\n",
       "                                      babbage_search class_id  \\\n",
       "0  [-0.00232666521333158, 0.019198870286345482, 0...        0   \n",
       "1  [-0.006104097235947847, 0.020085038617253304, ...        0   \n",
       "2  [-0.01456734724342823, 0.03029645048081875, -0...        0   \n",
       "3  [-0.008064398542046547, 0.012981051579117775, ...        0   \n",
       "4  [0.003970459569245577, 0.013751459307968616, -...        0   \n",
       "\n",
       "                                              prompt  \n",
       "0  Supplier: Creative Video Productions Ltd; Desc...  \n",
       "1  Supplier: NLS Foundation; Description: Grant P...  \n",
       "2  Supplier: British Library; Description: Legal ...  \n",
       "3  Supplier: ALDL; Description: Legal Deposit Ser...  \n",
       "4  Supplier: AM Phillip; Description: Vehicle Pur...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_df_with_class = ft_prep_df.merge(class_df,left_on='Classification',right_on='class',how='inner')\n",
    "\n",
    "# 모델을 돕기 위해 각 완성품에 선행 공백을 추가합니다.\n",
    "# Adding a leading whitespace onto each completion to help the model\n",
    "ft_df_with_class['class_id'] = ft_df_with_class.apply(lambda x: ' ' + str(x['class_id']),axis=1)\n",
    "ft_df_with_class = ft_df_with_class.drop('class', axis=1)\n",
    "\n",
    "# 프롬프트가 종료되는 시점을 모델이 알 수 있도록 각 프롬프트 끝에 공통 구분 기호를 추가합니다.\n",
    "# Adding a common separator onto the end of each prompt so the model knows when a prompt is terminating\n",
    "ft_df_with_class['prompt'] = ft_df_with_class.apply(lambda x: x['combined'] + '\\n\\n###\\n\\n',axis=1)\n",
    "ft_df_with_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ordering</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supplier: John Graham Construction Ltd; Descri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supplier: John Graham Construction Ltd; Descri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supplier: ECG Facilities Service; Description:...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supplier: Insight Direct (UK) Ltd; Description...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supplier: John Graham Construction Ltd; Descri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     prompt completion\n",
       "ordering                                                              \n",
       "0         Supplier: John Graham Construction Ltd; Descri...          1\n",
       "0         Supplier: John Graham Construction Ltd; Descri...          1\n",
       "1         Supplier: ECG Facilities Service; Description:...          3\n",
       "1         Supplier: Insight Direct (UK) Ltd; Description...          1\n",
       "2         Supplier: John Graham Construction Ltd; Descri...          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 클래스에 여러 개의 관측값이 있는 경우 이 단계는 필요하지 않습니다.\n",
    "# 우리의 경우에는 그렇지 않으므로 데이터를 섞어 훈련 및 검증 세트에서 동일한 클래스를 얻을 수 있는 더 나은 기회를 제공합니다.\n",
    "# 유효성 검사 집합에 클래스가 적으면 미세 조정된 모델에 오류가 발생하므로 이 단계는 필수입니다.\n",
    "\n",
    "# This step is unnecessary if you have a number of observations in each class\n",
    "# In our case we don't, so we shuffle the data to give us a better chance of getting equal classes in our train and validation sets\n",
    "# Our fine-tuned model will error if we have less classes in the validation set, so this is a necessary step\n",
    "\n",
    "import random \n",
    "\n",
    "labels = [x for x in ft_df_with_class['class_id']]\n",
    "text = [x for x in ft_df_with_class['prompt']]\n",
    "ft_df = pd.DataFrame(zip(text, labels), columns = ['prompt','class_id']) #[:300]\n",
    "ft_df.columns = ['prompt','completion']\n",
    "ft_df['ordering'] = ft_df.apply(lambda x: random.randint(0,len(ft_df)), axis = 1)\n",
    "ft_df.set_index('ordering',inplace=True)\n",
    "ft_df_sorted = ft_df.sort_index(ascending=True)\n",
    "ft_df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 101 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- There are 62 duplicated prompt-completion sets. These are rows: [1, 4, 5, 8, 11, 12, 15, 17, 20, 21, 22, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 46, 51, 52, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 83, 84, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98]\n",
      "- All prompts end with suffix `; Value: 0       26866\\n1       74806\\n2       56448\\n3      164691\\n4       27926\\n        ...  \\n96      26832\\n97      40800\\n98     144330\\n99      49827\\n100     26604\\nName: Transaction value (£), Length: 101, dtype: int64\\n\\n###\\n\\n`. This suffix seems very long. Consider replacing with a shorter suffix, such as `\\n\\n===\\n\\n`\n",
      "- All prompts start with prefix `Supplier: `\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 62 duplicate rows [Y/n]: Y\n",
      "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified files to `transactions_grouped_prepared_train (1).jsonl` and `transactions_grouped_prepared_valid (1).jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"transactions_grouped_prepared_train (1).jsonl\" -v \"transactions_grouped_prepared_valid (1).jsonl\" --compute_classification_metrics --classification_n_classes 5\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `; Value: 0       26866\\n1       74806\\n2       56448\\n3      164691\\n4       27926\\n        ...  \\n96      26832\\n97      40800\\n98     144330\\n99      49827\\n100     26604\\nName: Transaction value (£), Length: 101, dtype: int64\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt.\n",
      "Once your model starts training, it'll approximately take 3.27 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "# 이 단계는 이 분류기에 대한 훈련/검증 세트를 이미 생성한 경우 기존 파일을 제거하는 단계입니다.\n",
    "# This step is to remove any existing files if we've already produced training/validation sets for this classifier\n",
    "#!rm transactions_grouped*\n",
    "\n",
    "# 셔플된 데이터 프레임을 .jsonl 파일로 출력하고 prepare_data 함수를 실행하여 입력 파일을 가져옵니다.\n",
    "# We output our shuffled dataframe to a .jsonl file and run the prepare_data function to get us our input files\n",
    "ft_df_sorted.to_json(\"transactions_grouped.jsonl\", orient='records', lines=True)\n",
    "!openai tools fine_tunes.prepare_data -f transactions_grouped.jsonl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 이 함수는 준비된 두 파일에 클래스가 모두 나타나는지 확인합니다.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 그렇지 않으면 미세 조정된 모델 생성에 실패합니다.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This functions checks that your classes all appear in both prepared files\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# If they don't, the fine-tuned model creation will fail\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcheck_classes\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransactions_grouped_prepared_train.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransactions_grouped_prepared_valid.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'check_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# 이 함수는 준비된 두 파일에 클래스가 모두 나타나는지 확인합니다.\n",
    "# 그렇지 않으면 미세 조정된 모델 생성에 실패합니다.\n",
    "# This functions checks that your classes all appear in both prepared files\n",
    "# If they don't, the fine-tuned model creation will fail\n",
    "check_classes('transactions_grouped_prepared_train.jsonl','transactions_grouped_prepared_valid.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Upload progress: 100%|████████████████████| 10.3k/10.3k [00:00<00:00, 7.23Mit/s]\n",
      "Uploaded file from transactions_grouped_prepared_train.jsonl: file-Hk3CMmX8PL59zqvkWtY6gcVf\n",
      "Upload progress: 100%|████████████████████| 2.67k/2.67k [00:00<00:00, 4.83Mit/s]\n",
      "Uploaded file from transactions_grouped_prepared_valid.jsonl: file-zbFaBt9wcNvZlyOSQKltHRoq\n",
      "Created fine-tune: ft-w0TiyIpkRULKFjzn6PPF99Gy\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-03-14 07:46:31] Created fine-tune: ft-w0TiyIpkRULKFjzn6PPF99Gy\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-w0TiyIpkRULKFjzn6PPF99Gy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This step creates your model\n",
    "!openai api fine_tunes.create -t \"transactions_grouped_prepared_train.jsonl\" -v \"transactions_grouped_prepared_valid.jsonl\" --compute_classification_metrics --classification_n_classes 5 -m curie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congrats, you've got a fine-tuned model!\n",
    "# Copy/paste the name provided into the variable below and we'll take it for a spin\n",
    "fine_tuned_model = 'curie:ft-personal-2022-10-20-10-42-56'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미세 조정된 분류기 적용하기\n",
    "\n",
    "이제 분류기를 적용하여 성능을 확인해 보겠습니다. 훈련 집합에는 31개의 고유한 관측값만 있고 검증 집합에는 8개가 있으므로 성능이 어떤지 살펴보겠습니다.\n",
    "\n",
    "---------\n",
    "\n",
    "Now we'll apply our classifier to see how it performs. We only had 31 unique observations in our training set and 8 in our validation set, so lets see how the performance is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supplier: Flexiform; Description: Kelvin Hall;...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supplier: M &amp; J Ballantyne Ltd; Description: G...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supplier: Wavetek Ltd; Description: Kelvin Hal...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Supplier: Glasgow City Council; Description: K...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Supplier: Morris &amp; Spottiswood Ltd; Descriptio...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  completion\n",
       "0  Supplier: Flexiform; Description: Kelvin Hall;...           3\n",
       "1  Supplier: M & J Ballantyne Ltd; Description: G...           3\n",
       "2  Supplier: Wavetek Ltd; Description: Kelvin Hal...           3\n",
       "3  Supplier: Glasgow City Council; Description: K...           3\n",
       "4  Supplier: Morris & Spottiswood Ltd; Descriptio...           3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_json('transactions_grouped_prepared_valid.jsonl', lines=True)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "That model does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_class\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtest_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfine_tuned_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m test_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_set\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_class\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_class\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_set\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfine_tuned_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m test_set[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_set\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_class\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openai/api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    680\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    683\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: That model does not exist"
     ]
    }
   ],
   "source": [
    "test_set['predicted_class'] = test_set.apply(lambda x: openai.Completion.create(model=fine_tuned_model, prompt=x['prompt'], max_tokens=1, temperature=0, logprobs=5),axis=1)\n",
    "test_set['pred'] = test_set.apply(lambda x : x['predicted_class']['choices'][0]['text'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['result'] = test_set.apply(lambda x: str(x['pred']).strip() == str(x['completion']).strip(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['result'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "성능은 좋지 않습니다 - 안타깝게도 이는 예상된 결과입니다. 각 클래스의 예가 몇 개 밖에 없는 경우 임베딩과 기존 분류기를 사용한 위의 접근 방식이 더 효과적이었습니다.\n",
    "\n",
    "미세 조정된 모델은 레이블이 지정된 관측값이 많을 때 가장 잘 작동합니다. 수백 개 또는 수천 개가 있다면 더 나은 결과를 얻을 수 있지만, 홀드아웃 집합에서 마지막으로 테스트를 수행하여 새로운 관찰 집합에 잘 일반화되지 않는지 확인해 보겠습니다.\n",
    "\n",
    "-----------\n",
    "\n",
    "Performance is not great - unfortunately this is expected. With only a few examples of each class, the above approach with embeddings and a traditional classifier worked better.\n",
    "\n",
    "A fine-tuned model works best with a great number of labelled observations. If we had a few hundred or thousand we may get better results, but lets do one last test on a holdout set to confirm that it doesn't generalise well to a new set of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_df = transactions.copy().iloc[101:]\n",
    "holdout_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'holdout_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m holdout_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupplier: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mholdout_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupplier\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m; Description: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m holdout_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m###\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# + \"; Value: \" + str(df['Transaction value (£)']).strip()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m holdout_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction_result\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m holdout_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(model\u001b[38;5;241m=\u001b[39mfine_tuned_model, prompt\u001b[38;5;241m=\u001b[39mx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined\u001b[39m\u001b[38;5;124m'\u001b[39m], max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, logprobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m),axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m holdout_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m holdout_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction_result\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'holdout_df' is not defined"
     ]
    }
   ],
   "source": [
    "holdout_df['combined'] = \"Supplier: \" + holdout_df['Supplier'].str.strip() + \"; Description: \" + holdout_df['Description'].str.strip() + '\\n\\n###\\n\\n' # + \"; Value: \" + str(df['Transaction value (£)']).strip()\n",
    "holdout_df['prediction_result'] = holdout_df.apply(lambda x: openai.Completion.create(model=fine_tuned_model, prompt=x['combined'], max_tokens=1, temperature=0, logprobs=5),axis=1)\n",
    "holdout_df['pred'] = holdout_df.apply(lambda x : x['prediction_result']['choices'][0]['text'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'holdout_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mholdout_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'holdout_df' is not defined"
     ]
    }
   ],
   "source": [
    "holdout_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2    231\n",
       " 0     27\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_df['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 결과도 마찬가지로 실망스러운 수준이었으며, 레이블이 지정된 관측값이 적은 데이터 세트의 경우 제로 샷 분류나 임베딩을 사용한 기존 분류가 미세 조정된 모델보다 더 나은 결과를 가져온다는 사실을 알게 되었습니다.\n",
    "\n",
    "미세 조정 모델은 여전히 훌륭한 도구이지만, 분류하려는 각 클래스에 대해 레이블이 지정된 예시 수가 많을 때 더 효과적입니다.\n",
    "\n",
    "------------------\n",
    "\n",
    "Well those results were similarly underwhelming - so we've learned that with a dataset with a small number of labelled observations, either zero-shot classification or traditional classification with embeddings return better results than a fine-tuned model.\n",
    "\n",
    "A fine-tuned model is still a great tool, but is more effective when you have a larger number of labelled examples for each class that you're looking to classify"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
