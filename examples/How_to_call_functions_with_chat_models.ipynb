{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# 채팅 모델로 함수를 호출하는 방법\n",
    "\n",
    "이 노트북에서는 채팅 완료 API를 외부 함수와 함께 사용하여 GPT 모델의 기능을 확장하는 방법을 다룹니다.\n",
    "\n",
    "`functions` 는 채팅 완료 API의 선택적 파라미터로 함수 사양을 제공하는 데 사용할 수 있습니다. 그 목적은 모델이 제공된 사양을 준수하는 함수 인수를 생성할 수 있도록 하기 위함입니다. API가 실제로 함수 호출을 실행하지는 않는다는 점에 유의하세요. 모델 출력을 사용하여 함수 호출을 실행하는 것은 개발자의 몫입니다.\n",
    "\n",
    "`functions` 매개변수가 제공되면 기본적으로 모델이 함수 중 하나를 사용하는 것이 적절한 시기를 결정합니다. API는 `function_call` 파라미터를 `{\"name\": \"<인서트 함수 이름>\"}`로 설정할 수 있습니다. 또한 `function_call` 파라미터를 `\"none\"`으로 설정하여 API가 함수를 사용하지 않도록 강제할 수도 있습니다. 함수가 사용된 경우 출력에 `\"finish_reason\"`이 포함됩니다: `function_call\"`과 함께 함수 이름과 생성된 함수 인수가 포함된 `function_call` 객체가 응답에 포함됩니다.\n",
    "\n",
    "### 개요\n",
    "\n",
    "이 노트북은 다음 두 섹션으로 구성되어 있습니다:\n",
    "\n",
    "- **함수 인수를 생성하는 방법:** 함수 집합을 지정하고 API를 사용하여 함수 인수를 생성합니다. \n",
    "- **모델 생성 인수를 사용하여 함수를 호출하는 방법:** 모델 생성 인수를 사용하여 함수를 실제로 실행하여 루프를 닫습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c85e26",
   "metadata": {},
   "source": [
    "## 함수 인수를 생성하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e71f33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from scipy) (1.24.3)\n",
      "Requirement already satisfied: tenacity in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (8.2.2)\n",
      "Requirement already satisfied: tiktoken in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "Requirement already satisfied: termcolor in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: openai in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: requests in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests) (2023.5.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "!pip install tenacity\n",
    "!pip install tiktoken\n",
    "!pip install termcolor \n",
    "!pip install openai\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from termcolor import colored\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "### 유틸리티\n",
    "\n",
    "먼저 채팅 완료 API를 호출하고 대화 상태를 유지 및 추적하기 위한 몇 가지 유틸리티를 정의해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "745ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, function_call=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    if function_call is not None:\n",
    "        json_data.update({\"function_call\": function_call})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d1c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_conversation(messages):\n",
    "    role_to_color = {\n",
    "        \"system\": \"red\",\n",
    "        \"user\": \"green\",\n",
    "        \"assistant\": \"blue\",\n",
    "        \"function\": \"magenta\",\n",
    "    }\n",
    "    formatted_messages = []\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            formatted_messages.append(f\"system: {message['content']}\\n\")\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            formatted_messages.append(f\"user: {message['content']}\\n\")\n",
    "        elif message[\"role\"] == \"assistant\" and message.get(\"function_call\"):\n",
    "            formatted_messages.append(f\"assistant: {message['function_call']}\\n\")\n",
    "        elif message[\"role\"] == \"assistant\" and not message.get(\"function_call\"):\n",
    "            formatted_messages.append(f\"assistant: {message['content']}\\n\")\n",
    "        elif message[\"role\"] == \"function\":\n",
    "            formatted_messages.append(f\"function ({message['name']}): {message['content']}\\n\")\n",
    "    for formatted_message in formatted_messages:\n",
    "        print(\n",
    "            colored(\n",
    "                formatted_message,\n",
    "                role_to_color[messages[formatted_messages.index(formatted_message)][\"role\"]],\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "### 기본 개념\n",
    "\n",
    "가상의 날씨 API와 인터페이스하기 위한 몇 가지 함수 사양을 만들어 보겠습니다. 이 함수 사양을 채팅 완성 API에 전달하여 사양을 준수하는 함수 인수를 생성하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e25069",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_n_day_weather_forecast\",\n",
    "        \"description\": \"Get an N-day weather forecast\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "                \"num_days\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The number of days to forecast\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc39899",
   "metadata": {},
   "source": [
    "모델에게 현재 날씨에 대해 질문하면 몇 가지 명확한 질문으로 응답합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518d6827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'Sure, I can help you with that. Could you please provide me with the city and state where you are located?'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's the weather like today\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c999375",
   "metadata": {},
   "source": [
    "누락된 정보를 제공하면 적절한 함수 인수를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c42a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_current_weather',\n",
       "  'arguments': '{\\n  \"location\": \"Glasgow, Scotland\",\\n  \"format\": \"celsius\"\\n}'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"I'm in Glasgow, Scotland.\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d4762",
   "metadata": {},
   "source": [
    "프롬프트를 다르게 표시하면 앞서 설명한 다른 기능을 타겟팅하도록 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa232e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': \"Sure, I can help you with that. Can you please provide the number of days you'd like to see the weather forecast for?\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"what is the weather going to be like in Glasgow, Scotland over the next x days\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6172ddac",
   "metadata": {},
   "source": [
    "다시 한 번, 모델에 아직 충분한 정보가 없기 때문에 설명을 요청하고 있습니다. 이 경우 예보의 위치는 이미 알고 있지만 예보에 필요한 일수를 알아야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7d8a543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 0,\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'function_call': {'name': 'get_n_day_weather_forecast',\n",
       "   'arguments': '{\\n  \"location\": \"Glasgow, Scotland\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 5\\n}'}},\n",
       " 'finish_reason': 'function_call'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"5 days\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "chat_response.json()[\"choices\"][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b758a0a",
   "metadata": {},
   "source": [
    "#### 특정 기능 사용 강제 또는 기능 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f79ba",
   "metadata": {},
   "source": [
    "function_call 인수를 사용하여 모델이 특정 함수(예: get_n_day_weather_forecast)를 사용하도록 강제할 수 있습니다. 이렇게 하면 모델이 함수를 사용하는 방법에 대한 가정을 하도록 강제할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559371b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_n_day_weather_forecast',\n",
       "  'arguments': '{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\",\\n  \"num_days\": 1\\n}'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this cell we force the model to use get_n_day_weather_forecast\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions, function_call={\"name\": \"get_n_day_weather_forecast\"}\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ab0f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': None,\n",
       " 'function_call': {'name': 'get_current_weather',\n",
       "  'arguments': '{\\n\"location\": \"Toronto, Canada\",\\n\"format\": \"celsius\"\\n}'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we don't force the model to use get_n_day_weather_forecast it may not\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me a weather report for Toronto, Canada.\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd70e48",
   "metadata": {},
   "source": [
    "모델이 함수를 전혀 사용하지 않도록 강제할 수도 있습니다. 이렇게 하면 적절한 함수 호출을 생성하지 못하게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acfe54e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '{\\n  \"location\": \"Toronto, Canada\",\\n  \"format\": \"celsius\"\\n}'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Give me the current weather (use Celcius) for Toronto, Canada.\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, functions=functions, function_call=\"none\"\n",
    ")\n",
    "chat_response.json()[\"choices\"][0][\"message\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4482aee",
   "metadata": {},
   "source": [
    "## 모델 생성 인수를 사용하여 함수를 호출하는 방법\n",
    "\n",
    "다음 예제에서는 입력이 모델 생성된 함수를 실행하고 이를 사용하여 데이터베이스에 대한 질문에 답할 수 있는 에이전트를 구현하는 방법을 보여드리겠습니다. 간단하게 설명하기 위해 [치누크 샘플 데이터베이스](https://www.sqlitetutorial.net/sqlite-sample-database/)를 사용하겠습니다.\n",
    "\n",
    "*참고:* 모델이 올바른 SQL을 생성하는 데 완벽하게 신뢰할 수 없기 때문에 프로덕션 환경에서는 SQL 생성의 위험이 높을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7654fef",
   "metadata": {},
   "source": [
    "### SQL 쿼리 실행을 위한 함수 지정하기\n",
    "\n",
    "먼저 SQLite 데이터베이스에서 데이터를 추출하는 데 유용한 몇 가지 유틸리티 함수를 정의해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f6b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"data/Chinook.db\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abec0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_names(conn):\n",
    "    \"\"\"Return a list of table names.\"\"\"\n",
    "    table_names = []\n",
    "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    for table in tables.fetchall():\n",
    "        table_names.append(table[0])\n",
    "    return table_names\n",
    "\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Return a list of column names.\"\"\"\n",
    "    column_names = []\n",
    "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
    "    for col in columns:\n",
    "        column_names.append(col[1])\n",
    "    return column_names\n",
    "\n",
    "\n",
    "def get_database_info(conn):\n",
    "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
    "    table_dicts = []\n",
    "    for table_name in get_table_names(conn):\n",
    "        columns_names = get_column_names(conn, table_name)\n",
    "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
    "    return table_dicts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6e5ea",
   "metadata": {},
   "source": [
    "이제 이러한 유틸리티 함수를 사용하여 데이터베이스 스키마의 표현을 추출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c0104cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_schema_dict = get_database_info(conn)\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [\n",
    "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
    "        for table in database_schema_dict\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73c9ee",
   "metadata": {},
   "source": [
    "이전과 마찬가지로 API가 인수를 생성하도록 할 함수에 대한 함수 사양을 정의하겠습니다. 함수 사양에 데이터베이스 스키마를 삽입하고 있다는 점에 주목하세요. 이는 모델이 알아야 할 중요한 정보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0258813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"ask_database\",\n",
    "        \"description\": \"Use this function to answer user questions about music. Output should be a fully formed SQL query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            SQL query extracting info to answer the user's question.\n",
    "                            SQL should be written using this database schema:\n",
    "                            {database_schema_string}\n",
    "                            The query should be returned in plain text, not in JSON.\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08c121",
   "metadata": {},
   "source": [
    "### SQL 쿼리 실행하기\n",
    "\n",
    "이제 데이터베이스에 대해 실제로 쿼리를 실행하는 함수를 구현해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65585e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_database(conn, query):\n",
    "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
    "    try:\n",
    "        results = str(conn.execute(query).fetchall())\n",
    "    except Exception as e:\n",
    "        results = f\"query failed with error: {e}\"\n",
    "    return results\n",
    "\n",
    "def execute_function_call(message):\n",
    "    if message[\"function_call\"][\"name\"] == \"ask_database\":\n",
    "        query = eval(message[\"function_call\"][\"arguments\"])[\"query\"]\n",
    "        results = ask_database(conn, query)\n",
    "    else:\n",
    "        results = f\"Error: function {message['function_call']['name']} does not exist\"\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38c55083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Answer user questions by generating SQL queries against the Chinook Music Database.\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, who are the top 5 artists by number of tracks?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT Artist.Name, COUNT(Track.TrackId) as num_tracks FROM Artist JOIN Album ON Artist.ArtistId = Album.ArtistId JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Artist.Name ORDER BY num_tracks DESC LIMIT 5\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Answer user questions by generating SQL queries against the Chinook Music Database.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Hi, who are the top 5 artists by number of tracks?\"})\n",
    "chat_response = chat_completion_request(messages, functions)\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "if assistant_message.get(\"function_call\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\"role\": \"function\", \"name\": assistant_message[\"function_call\"][\"name\"], \"content\": results})\n",
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "710481dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: Answer user questions by generating SQL queries against the Chinook Music Database.\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, who are the top 5 artists by number of tracks?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT Artist.Name, COUNT(Track.TrackId) as num_tracks FROM Artist JOIN Album ON Artist.ArtistId = Album.ArtistId JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Artist.Name ORDER BY num_tracks DESC LIMIT 5\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\u001b[0m\n",
      "\u001b[32muser: What is the name of the album with the most tracks?\n",
      "\u001b[0m\n",
      "\u001b[34massistant: {'name': 'ask_database', 'arguments': '{\\n  \"query\": \"SELECT Album.Title, COUNT(Track.TrackId) as num_tracks FROM Album JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Album.Title ORDER BY num_tracks DESC LIMIT 1\"\\n}'}\n",
      "\u001b[0m\n",
      "\u001b[35mfunction (ask_database): [('Greatest Hits', 57)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"What is the name of the album with the most tracks?\"})\n",
    "chat_response = chat_completion_request(messages, functions)\n",
    "assistant_message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "messages.append(assistant_message)\n",
    "if assistant_message.get(\"function_call\"):\n",
    "    results = execute_function_call(assistant_message)\n",
    "    messages.append({\"role\": \"function\", \"content\": results, \"name\": assistant_message[\"function_call\"][\"name\"]})\n",
    "pretty_print_conversation(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d89073c",
   "metadata": {},
   "source": [
    "## 다음 단계\n",
    "\n",
    "지식창고와 대화식으로 상호작용하기 위해 채팅 완성 API 및 지식 검색 기능을 사용하는 방법을 보여주는 다른 [노트북](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_call_functions_for_knowledge_retrieval.ipynb)을 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83138e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
