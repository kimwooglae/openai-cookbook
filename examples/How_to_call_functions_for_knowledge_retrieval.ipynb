{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# 지식창고로 함수를 사용하는 방법\n",
    "\n",
    "이 노트북에서는 지식창고에 액세스할 수 있는 에이전트와 사용자 요구 사항에 따라 호출할 수 있는 두 개의 함수를 만들어 [인수 생성]('How_to_generate_function_arguments_with_chat_models.ipynb') 노트북의 개념을 기반으로 합니다.\n",
    "\n",
    "학술 주제에 대한 질문에 답하기 위해 arXiv의 데이터를 사용하는 에이전트를 만들어 보겠습니다. 이 에이전트에는 다음과 같은 두 가지 함수가 있습니다: \n",
    "\n",
    "- **get_articles:** 주제에 대한 arXiv 논문을 가져와 링크와 함께 사용자에게 요약하는 함수 \n",
    "- **read_article_and_summarize**: 이 기능은 이전에 검색한 논문 중 하나를 가져와 전체 내용을 읽고 핵심 주장, 증거 및 결론을 요약합니다.\n",
    "\n",
    "이렇게 하면 여러 서비스 중에서 선택할 수 있고 첫 번째 함수의 데이터 중 일부가 두 번째 함수에서 계속 사용되는 다기능 워크플로우에 익숙해질 수 있습니다.\n",
    "\n",
    "## 연습\n",
    "\n",
    "이 쿡북에서는 다음과 같은 워크플로우를 안내합니다:\n",
    "\n",
    "- **검색 유틸리티:** 답변을 얻기 위해 arXiv에 액세스하는 두 가지 함수 만들기 \n",
    "- **에이전트 구성:** 함수의 필요성을 평가하고, 필요한 경우 해당 함수를 호출하여 결과를 에이전트에게 다시 제시하는 에이전트 동작 구축 \n",
    "- **arXiv 대화:** 이 모든 것을 실시간 대화에 통합하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80e71f33",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from scipy) (1.24.3)\n",
      "Requirement already satisfied: tenacity in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (8.2.2)\n",
      "Requirement already satisfied: tiktoken==0.3.3 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from tiktoken==0.3.3) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from tiktoken==0.3.3) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.3.3) (2023.5.7)\n",
      "Requirement already satisfied: termcolor in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: openai in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: requests in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: arxiv in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (1.4.7)\n",
      "Requirement already satisfied: feedparser in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from arxiv) (6.0.10)\n",
      "Requirement already satisfied: sgmllib3k in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from feedparser->arxiv) (1.0.0)\n",
      "Requirement already satisfied: pandas in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: PyPDF2 in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: tqdm in /Users/wlkim/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "!pip install tenacity\n",
    "!pip install tiktoken==0.3.3\n",
    "!pip install termcolor \n",
    "!pip install openai\n",
    "!pip install requests\n",
    "!pip install arxiv\n",
    "!pip install pandas\n",
    "!pip install PyPDF2\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import ast\n",
    "import concurrent\n",
    "from csv import writer\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import requests\n",
    "from scipy import spatial\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import tiktoken\n",
    "from tqdm import tqdm\n",
    "from termcolor import colored\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-16k-0613\"\n",
    "# GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e47962",
   "metadata": {},
   "source": [
    "## 검색 유틸리티\n",
    "\n",
    "먼저 두 가지 기능을 뒷받침할 몇 가지 유틸리티를 설정하겠습니다.\n",
    "\n",
    "다운로드한 논문은 디렉토리에 저장됩니다(여기서는 ```./data/papers```을 사용합니다). 다운로드한 논문의 임베딩과 세부 정보를 저장하여 ```summarize_text```를 사용하여 검색할 수 있도록 ``arxiv_library.csv`` 파일을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2de5d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a directory to store downloaded papers\n",
    "data_dir = os.path.join(os.curdir, \"data\", \"papers\")\n",
    "paper_dir_filepath = \"./data/arxiv_library.csv\"\n",
    "\n",
    "# Generate a blank dataframe where we can store downloaded files\n",
    "df = pd.DataFrame(list())\n",
    "df.to_csv(paper_dir_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57217b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def embedding_request(text):\n",
    "    response = openai.Embedding.create(input=text, model=EMBEDDING_MODEL)\n",
    "    return response\n",
    "\n",
    "\n",
    "def get_articles(query, library=paper_dir_filepath, top_k=5):\n",
    "    \"\"\"This function gets the top_k articles based on a user's query, sorted by relevance.\n",
    "    It also downloads the files and stores them in arxiv_library.csv to be retrieved by the read_article_and_summarize.\n",
    "    \"\"\"\n",
    "    search = arxiv.Search(\n",
    "        query=query, max_results=top_k, sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    result_list = []\n",
    "    for result in search.results():\n",
    "        result_dict = {}\n",
    "        result_dict.update({\"title\": result.title})\n",
    "        result_dict.update({\"summary\": result.summary})\n",
    "\n",
    "        # Taking the first url provided\n",
    "        result_dict.update({\"article_url\": [x.href for x in result.links][0]})\n",
    "        result_dict.update({\"pdf_url\": [x.href for x in result.links][1]})\n",
    "        result_list.append(result_dict)\n",
    "\n",
    "        # Store references in library file\n",
    "        response = embedding_request(text=result.title)\n",
    "        file_reference = [\n",
    "            result.title,\n",
    "            result.download_pdf(data_dir),\n",
    "            response[\"data\"][0][\"embedding\"],\n",
    "        ]\n",
    "\n",
    "        # Write to file\n",
    "        with open(library, \"a\") as f_object:\n",
    "            writer_object = writer(f_object)\n",
    "            writer_object.writerow(file_reference)\n",
    "            f_object.close()\n",
    "    return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda02bdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Proximal Policy Optimization and its Dynamic Version for Sequence Generation',\n",
       " 'summary': 'In sequence generation task, many works use policy gradient for model\\noptimization to tackle the intractable backpropagation issue when maximizing\\nthe non-differentiable evaluation metrics or fooling the discriminator in\\nadversarial learning. In this paper, we replace policy gradient with proximal\\npolicy optimization (PPO), which is a proved more efficient reinforcement\\nlearning algorithm, and propose a dynamic approach for PPO (PPO-dynamic). We\\ndemonstrate the efficacy of PPO and PPO-dynamic on conditional sequence\\ngeneration tasks including synthetic experiment and chit-chat chatbot. The\\nresults show that PPO and PPO-dynamic can beat policy gradient by stability and\\nperformance.',\n",
       " 'article_url': 'http://arxiv.org/abs/1808.07982v1',\n",
       " 'pdf_url': 'http://arxiv.org/pdf/1808.07982v1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the search is working\n",
    "result_output = get_articles(\"ppo reinforcement learning\")\n",
    "result_output[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca725b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Proximal Policy Optimization and its Dynamic Version for Sequence Generation',\n",
       "  'summary': 'In sequence generation task, many works use policy gradient for model\\noptimization to tackle the intractable backpropagation issue when maximizing\\nthe non-differentiable evaluation metrics or fooling the discriminator in\\nadversarial learning. In this paper, we replace policy gradient with proximal\\npolicy optimization (PPO), which is a proved more efficient reinforcement\\nlearning algorithm, and propose a dynamic approach for PPO (PPO-dynamic). We\\ndemonstrate the efficacy of PPO and PPO-dynamic on conditional sequence\\ngeneration tasks including synthetic experiment and chit-chat chatbot. The\\nresults show that PPO and PPO-dynamic can beat policy gradient by stability and\\nperformance.',\n",
       "  'article_url': 'http://arxiv.org/abs/1808.07982v1',\n",
       "  'pdf_url': 'http://arxiv.org/pdf/1808.07982v1'},\n",
       " {'title': 'CIM-PPO:Proximal Policy Optimization with Liu-Correntropy Induced Metric',\n",
       "  'summary': \"As an algorithm based on deep reinforcement learning, Proximal Policy\\nOptimization (PPO) performs well in many complex tasks and has become one of\\nthe most popular RL algorithms in recent years. According to the mechanism of\\npenalty in surrogate objective, PPO can be divided into PPO with KL Divergence\\n(KL-PPO) and PPO with Clip function(Clip-PPO). Clip-PPO is widely used in a\\nvariety of practical scenarios and has attracted the attention of many\\nresearchers. Therefore, many variations have also been created, making the\\nalgorithm better and better. However, as a more theoretical algorithm, KL-PPO\\nwas neglected because its performance was not as good as CliP-PPO. In this\\narticle, we analyze the asymmetry effect of KL divergence on PPO's objective\\nfunction , and give the inequality that can indicate when the asymmetry will\\naffect the efficiency of KL-PPO. Proposed PPO with Correntropy Induced Metric\\nalgorithm(CIM-PPO) that use the theory of correntropy(a symmetry metric method\\nthat was widely used in M-estimation to evaluate two distributions'\\ndifference)and applied it in PPO. Then, we designed experiments based on\\nOpenAIgym to test the effectiveness of the new algorithm and compare it with\\nKL-PPO and CliP-PPO.\",\n",
       "  'article_url': 'http://arxiv.org/abs/2110.10522v2',\n",
       "  'pdf_url': 'http://arxiv.org/pdf/2110.10522v2'},\n",
       " {'title': 'A2C is a special case of PPO',\n",
       "  'summary': \"Advantage Actor-critic (A2C) and Proximal Policy Optimization (PPO) are\\npopular deep reinforcement learning algorithms used for game AI in recent\\nyears. A common understanding is that A2C and PPO are separate algorithms\\nbecause PPO's clipped objective appears significantly different than A2C's\\nobjective. In this paper, however, we show A2C is a special case of PPO. We\\npresent theoretical justifications and pseudocode analysis to demonstrate why.\\nTo validate our claim, we conduct an empirical experiment using\\n\\\\texttt{Stable-baselines3}, showing A2C and PPO produce the \\\\textit{exact} same\\nmodels when other settings are controlled.\",\n",
       "  'article_url': 'http://arxiv.org/abs/2205.09123v1',\n",
       "  'pdf_url': 'http://arxiv.org/pdf/2205.09123v1'},\n",
       " {'title': 'Proximal Policy Optimization via Enhanced Exploration Efficiency',\n",
       "  'summary': \"Proximal policy optimization (PPO) algorithm is a deep reinforcement learning\\nalgorithm with outstanding performance, especially in continuous control tasks.\\nBut the performance of this method is still affected by its exploration\\nability. For classical reinforcement learning, there are some schemes that make\\nexploration more full and balanced with data exploitation, but they can't be\\napplied in complex environments due to the complexity of algorithm. Based on\\ncontinuous control tasks with dense reward, this paper analyzes the assumption\\nof the original Gaussian action exploration mechanism in PPO algorithm, and\\nclarifies the influence of exploration ability on performance. Afterward,\\naiming at the problem of exploration, an exploration enhancement mechanism\\nbased on uncertainty estimation is designed in this paper. Then, we apply\\nexploration enhancement theory to PPO algorithm and propose the proximal policy\\noptimization algorithm with intrinsic exploration module (IEM-PPO) which can be\\nused in complex environments. In the experimental parts, we evaluate our method\\non multiple tasks of MuJoCo physical simulator, and compare IEM-PPO algorithm\\nwith curiosity driven exploration algorithm (ICM-PPO) and original algorithm\\n(PPO). The experimental results demonstrate that IEM-PPO algorithm needs longer\\ntraining time, but performs better in terms of sample efficiency and cumulative\\nreward, and has stability and robustness.\",\n",
       "  'article_url': 'http://arxiv.org/abs/2011.05525v1',\n",
       "  'pdf_url': 'http://arxiv.org/pdf/2011.05525v1'},\n",
       " {'title': 'Neural PPO-Clip Attains Global Optimality: A Hinge Loss Perspective',\n",
       "  'summary': 'Policy optimization is a fundamental principle for designing reinforcement\\nlearning algorithms, and one example is the proximal policy optimization\\nalgorithm with a clipped surrogate objective (PPO-Clip), which has been\\npopularly used in deep reinforcement learning due to its simplicity and\\neffectiveness. Despite its superior empirical performance, PPO-Clip has not\\nbeen justified via theoretical proof up to date. In this paper, we establish\\nthe first global convergence rate of PPO-Clip under neural function\\napproximation. We identify the fundamental challenges of analyzing PPO-Clip and\\naddress them with the two core ideas: (i) We reinterpret PPO-Clip from the\\nperspective of hinge loss, which connects policy improvement with solving a\\nlarge-margin classification problem with hinge loss and offers a generalized\\nversion of the PPO-Clip objective. (ii) Based on the above viewpoint, we\\npropose a two-step policy improvement scheme, which facilitates the convergence\\nanalysis by decoupling policy search from the complex neural policy\\nparameterization with the help of entropic mirror descent and a\\nregression-based policy update scheme. Moreover, our theoretical results\\nprovide the first characterization of the effect of the clipping mechanism on\\nthe convergence of PPO-Clip. Through experiments, we empirically validate the\\nreinterpretation of PPO-Clip and the generalized objective with various\\nclassifiers on various RL benchmark tasks.',\n",
       "  'article_url': 'http://arxiv.org/abs/2110.13799v4',\n",
       "  'pdf_url': 'http://arxiv.org/pdf/2110.13799v4'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140a3362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT',\n",
       " 'summary': 'In this paper, we aim to develop a large language model (LLM) with the\\nreasoning ability on complex graph data. Currently, LLMs have achieved very\\nimpressive performance on various natural language learning tasks, extensions\\nof which have also been applied to study the vision tasks with multi-modal\\ndata. However, when it comes to the graph learning tasks, existing LLMs present\\nvery serious flaws due to their several inherited weaknesses in performing\\n{multi-step logic reasoning}, {precise mathematical calculation} and\\n{perception about the spatial and temporal factors}.\\n  To address such challenges, in this paper, we will investigate the\\nprinciples, methodologies and algorithms to empower existing LLMs with graph\\nreasoning ability, which will have tremendous impacts on the current research\\nof both LLMs and graph learning. Inspired by the latest ChatGPT and Toolformer\\nmodels, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer)\\nframework to teach LLMs themselves with prompts augmented by ChatGPT to use\\nexternal graph reasoning API tools. Specifically, we will investigate to teach\\nGraph-ToolFormer to handle various graph data reasoning tasks in this paper,\\nincluding both (1) very basic graph data loading and graph property reasoning\\ntasks, ranging from simple graph order and size to the graph diameter and\\nperiphery, and (2) more advanced reasoning tasks on real-world graph data, such\\nas bibliographic networks, protein molecules, sequential recommender systems,\\nsocial networks and knowledge graphs.',\n",
       " 'article_url': 'http://arxiv.org/abs/2304.11116v3',\n",
       " 'pdf_url': 'http://arxiv.org/pdf/2304.11116v3'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the search is working\n",
    "result_output = get_articles(\"toolformer\")\n",
    "result_output[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11675627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100,\n",
    ") -> list[str]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = embedding_request(query)\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"filepath\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7211df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(filepath):\n",
    "    \"\"\"Takes a filepath to a PDF and returns a string of the PDF's contents\"\"\"\n",
    "    # creating a pdf reader object\n",
    "    reader = PdfReader(filepath)\n",
    "    pdf_text = \"\"\n",
    "    page_number = 0\n",
    "    for page in reader.pages:\n",
    "        page_number += 1\n",
    "        pdf_text += page.extract_text() + f\"\\nPage Number: {page_number}\"\n",
    "    return pdf_text\n",
    "\n",
    "\n",
    "# Split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "def create_chunks(text, n, tokenizer):\n",
    "    \"\"\"Returns successive n-sized chunks from provided text.\"\"\"\n",
    "    tokens = tokenizer.encode(text)\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "\n",
    "def extract_chunk(content, template_prompt):\n",
    "    \"\"\"This function applies a prompt to some input content. In this case it returns a summarize chunk of text\"\"\"\n",
    "    prompt = template_prompt + content\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL, messages=[{\"role\": \"user\", \"content\": prompt}], temperature=0\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def summarize_text(query):\n",
    "    \"\"\"This function does the following:\n",
    "    - Reads in the arxiv_library.csv file in including the embeddings\n",
    "    - Finds the closest file to the user's query\n",
    "    - Scrapes the text out of the file and chunks it\n",
    "    - Summarizes each chunk in parallel\n",
    "    - Does one final summary and returns this to the user\"\"\"\n",
    "\n",
    "    # A prompt to dictate how the recursive summarizations should approach the input paper\n",
    "    summary_prompt = \"\"\"Summarize this text from an academic paper. Extract any key points with reasoning.\\n\\nContent:\"\"\"\n",
    "\n",
    "    # If the library is empty (no searches have been performed yet), we perform one and download the results\n",
    "    library_df = pd.read_csv(paper_dir_filepath).reset_index()\n",
    "    if len(library_df) == 0:\n",
    "        print(\"No papers searched yet, downloading first.\")\n",
    "        get_articles(query)\n",
    "        print(\"Papers downloaded, continuing\")\n",
    "        library_df = pd.read_csv(paper_dir_filepath).reset_index()\n",
    "    library_df.columns = [\"title\", \"filepath\", \"embedding\"]\n",
    "    library_df[\"embedding\"] = library_df[\"embedding\"].apply(ast.literal_eval)\n",
    "    strings = strings_ranked_by_relatedness(query, library_df, top_n=1)\n",
    "    print(\"Chunking text from paper\")\n",
    "    pdf_text = read_pdf(strings[0])\n",
    "\n",
    "    # Initialise tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    results = \"\"\n",
    "\n",
    "    # Chunk up the document into 1500 token chunks\n",
    "    chunks = create_chunks(pdf_text, 1500, tokenizer)\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "    print(\"Summarizing each chunk of text\")\n",
    "\n",
    "    # Parallel process the summaries\n",
    "    with concurrent.futures.ThreadPoolExecutor(\n",
    "        max_workers=len(text_chunks)\n",
    "    ) as executor:\n",
    "        futures = [\n",
    "            executor.submit(extract_chunk, chunk, summary_prompt)\n",
    "            for chunk in text_chunks\n",
    "        ]\n",
    "        with tqdm(total=len(text_chunks)) as pbar:\n",
    "            for _ in concurrent.futures.as_completed(futures):\n",
    "                pbar.update(1)\n",
    "        for future in futures:\n",
    "            data = future.result()\n",
    "            results += data\n",
    "\n",
    "    # Final summary\n",
    "    print(\"Summarizing into overall summary\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Write a summary in Korean collated from this collection of key points extracted from an academic paper. Must use Korean.\n",
    "                        The summary should highlight the core argument, conclusions and evidence, and answer the user's query.\n",
    "                        User query: {query}\n",
    "                        The summary should be structured in bulleted lists following the headings Core Argument, Evidence, and Conclusions.\n",
    "                        Key points:\\n{results}\\nSummary:\\n\"\"\",\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "898b94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking text from paper\n",
      "Summarizing each chunk of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing into overall summary\n"
     ]
    }
   ],
   "source": [
    "# Test the summarize_text function works\n",
    "chat_test_response = summarize_text(\"PPO reinforcement learning sequence generation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c715f60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학술 논문은 시퀀스 생성 작업에서 Proximal Policy Optimization (PPO)의 사용에 대해 논의하고, 특히 챗봇의 대화 작업에서의 사용에 초점을 맞추고 있다. 저자들은 텍스트 생성 작업에서 일반적으로 사용되는 정책 기울기와 비교하여 PPO가 보다 효율적인 강화 학습 알고리즘이라고 주장한다. 저자들은 PPO의 동적 접근법 (PPO-dynamic)을 제안하고, 합성 실험과 챗봇 작업에서의 효과를 입증한다. 결과는 PPO와 PPO-dynamic이 안정성과 성능 측면에서 정책 기울기를 능가한다는 것을 보여준다. 이 논문은 또한 정책 기울기와 PPO에 대한 배경 정보를 제공하며, 텍스트 생성 분야에서의 관련 연구를 논의한다.\n",
      "\n",
      "핵심 주장:\n",
      "- PPO는 시퀀스 생성 작업에서 정책 기울기보다 더 효율적인 강화 학습 알고리즘이다.\n",
      "- PPO-dynamic은 PPO의 하이퍼파라미터를 동적으로 조정하여 최적화 과정을 개선한다.\n",
      "- PPO와 PPO-dynamic은 안정성과 성능 측면에서 정책 기울기를 능가한다.\n",
      "\n",
      "증거:\n",
      "- 합성 카운팅 작업에서 PPO-dynamic은 REINFORCE와 MIXER와 비교하여 높은 정확도 점수를 달성한다.\n",
      "- PPO-dynamic의 학습 곡선은 PPO보다 빠른 진전을 보인다.\n",
      "- 챗봇 작업에서 PPO-dynamic은 REINFORCE와 PPO보다 약간 높은 BLEU-2 점수를 달성한다.\n",
      "- PPO-dynamic의 학습 곡선은 정책 기울기보다 안정적이고 빠르다.\n",
      "\n",
      "결론:\n",
      "- PPO는 정책 기울기에 비해 시퀀스 학습에 더 나은 최적화 방법이다.\n",
      "- PPO-dynamic은 하이퍼파라미터를 동적으로 조정하여 최적화 과정을 개선한다.\n",
      "- 저자들은 PPO를 GAN 기반 시퀀스 학습의 새로운 최적화 방법으로 사용할 수 있으며, 이는 더 나은 성능을 제공한다고 결론 짓는다.\n"
     ]
    }
   ],
   "source": [
    "print(chat_test_response[\"choices\"][0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab07e98",
   "metadata": {},
   "source": [
    "## 에이전트 구성\n",
    "\n",
    "이 단계에서는 API를 여러 차례 사용할 수 있도록 지원하는 ```Conversation``` 클래스와 ```ChatCompletion``` API와 지식창고 함수 간의 상호 작용을 지원하는 몇 가지 Python 함수를 포함하여 에이전트를 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77a6fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73f7672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        message = {\"role\": role, \"content\": content}\n",
    "        self.conversation_history.append(message)\n",
    "\n",
    "    def display_conversation(self, detailed=False):\n",
    "        role_to_color = {\n",
    "            \"system\": \"red\",\n",
    "            \"user\": \"green\",\n",
    "            \"assistant\": \"blue\",\n",
    "            \"function\": \"magenta\",\n",
    "        }\n",
    "        for message in self.conversation_history:\n",
    "            print(\n",
    "                colored(\n",
    "                    f\"{message['role']}: {message['content']}\\n\\n\",\n",
    "                    role_to_color[message[\"role\"]],\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "978b7877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate our get_articles and read_article_and_summarize functions\n",
    "arxiv_functions = [\n",
    "    {\n",
    "        \"name\": \"get_articles\",\n",
    "        \"description\": \"\"\"Use this function to get academic papers from arXiv to answer user questions.\"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            User query in JSON. Responses should be summarized and should include the article URL reference\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "        \"name\": \"read_article_and_summarize\",\n",
    "        \"description\": \"\"\"Use this function to read whole papers and provide a summary for users.\n",
    "        You should NEVER call this function before get_articles has been called in the conversation.\"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": f\"\"\"\n",
    "                            Description of the article in plain text based on the user's query\n",
    "                            \"\"\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c88ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_completion_with_function_execution(messages, functions=[None]):\n",
    "    \"\"\"This function makes a ChatCompletion API call with the option of adding functions\"\"\"\n",
    "    response = chat_completion_request(messages, functions)\n",
    "    full_message = response.json()[\"choices\"][0]\n",
    "    if full_message[\"finish_reason\"] == \"function_call\":\n",
    "        print(f\"Function generation requested, calling function\")\n",
    "        return call_arxiv_function(messages, full_message)\n",
    "    else:\n",
    "        print(f\"Function not required, responding to user\")\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "def call_arxiv_function(messages, full_message):\n",
    "    \"\"\"Function calling function which executes function calls when the model believes it is necessary.\n",
    "    Currently extended by adding clauses to this if statement.\"\"\"\n",
    "\n",
    "    if full_message[\"message\"][\"function_call\"][\"name\"] == \"get_articles\":\n",
    "        try:\n",
    "            parsed_output = json.loads(\n",
    "                full_message[\"message\"][\"function_call\"][\"arguments\"]\n",
    "            )\n",
    "            print(\"Getting search results\")\n",
    "            results = get_articles(parsed_output[\"query\"])\n",
    "        except Exception as e:\n",
    "            print(parsed_output)\n",
    "            print(f\"Function execution failed\")\n",
    "            print(f\"Error message: {e}\")\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": full_message[\"message\"][\"function_call\"][\"name\"],\n",
    "                \"content\": str(results),\n",
    "            }\n",
    "        )\n",
    "        try:\n",
    "            print(\"Got search results, summarizing content\")\n",
    "            response = chat_completion_request(messages)\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(type(e))\n",
    "            raise Exception(\"Function chat request failed\")\n",
    "\n",
    "    elif (\n",
    "        full_message[\"message\"][\"function_call\"][\"name\"] == \"read_article_and_summarize\"\n",
    "    ):\n",
    "        parsed_output = json.loads(\n",
    "            full_message[\"message\"][\"function_call\"][\"arguments\"]\n",
    "        )\n",
    "        print(\"Finding and reading paper\")\n",
    "        summary = summarize_text(parsed_output[\"query\"])\n",
    "        return summary\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Function does not exist and cannot be called\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e7868",
   "metadata": {},
   "source": [
    "## arXiv 대화\n",
    "\n",
    "대화에서 함수를 테스트하여 이 모든 것을 종합해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c39a1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a system message\n",
    "paper_system_message = \"\"\"You are arXivGPT, a helpful assistant pulls academic papers to answer user questions.\n",
    "You summarize the papers clearly so the customer can decide which to read to answer their question.\n",
    "You always provide the article_url and title so the user can understand the name of the paper and click through to access it.\n",
    "Begin!\"\"\"\n",
    "paper_conversation = Conversation()\n",
    "paper_conversation.add_message(\"system\", paper_system_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "253fd0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function generation requested, calling function\n",
      "Finding and reading paper\n",
      "Chunking text from paper\n",
      "Summarizing each chunk of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 17/17 [00:32<00:00,  1.89s/it]\n"
     ]
    },
    {
     "ename": "ServiceUnavailableError",
     "evalue": "The server is overloaded or not ready yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceUnavailableError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Add a user message\u001b[39;00m\n\u001b[1;32m      2\u001b[0m paper_conversation\u001b[38;5;241m.\u001b[39madd_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi, how does PPO reinforcement learning work?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mchat_completion_with_function_execution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpaper_conversation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconversation_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marxiv_functions\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m assistant_message \u001b[38;5;241m=\u001b[39m chat_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m paper_conversation\u001b[38;5;241m.\u001b[39madd_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, assistant_message)\n",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m, in \u001b[0;36mchat_completion_with_function_execution\u001b[0;34m(messages, functions)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinish_reason\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction generation requested, calling function\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_arxiv_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction not required, responding to user\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[15], line 50\u001b[0m, in \u001b[0;36mcall_arxiv_function\u001b[0;34m(messages, full_message)\u001b[0m\n\u001b[1;32m     46\u001b[0m     parsed_output \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\n\u001b[1;32m     47\u001b[0m         full_message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinding and reading paper\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m     summary \u001b[38;5;241m=\u001b[39m \u001b[43msummarize_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_output\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m summary\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[9], line 88\u001b[0m, in \u001b[0;36msummarize_text\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     86\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[0;32m---> 88\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m         results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Final summary\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/openai-cookbook/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/openai-cookbook/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/openai-cookbook/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m, in \u001b[0;36mextract_chunk\u001b[0;34m(content, template_prompt)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This function applies a prompt to some input content. In this case it returns a summarize chunk of text\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m prompt \u001b[38;5;241m=\u001b[39m template_prompt \u001b[38;5;241m+\u001b[39m content\n\u001b[0;32m---> 37\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGPT_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/openai-cookbook/lib/python3.10/site-packages/openai/api_requestor.py:743\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OpenAIResponse(\u001b[38;5;28;01mNone\u001b[39;00m, rheaders)\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m503\u001b[39m:\n\u001b[0;32m--> 743\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mServiceUnavailableError(\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe server is overloaded or not ready yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    745\u001b[0m         rbody,\n\u001b[1;32m    746\u001b[0m         rcode,\n\u001b[1;32m    747\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrheaders,\n\u001b[1;32m    748\u001b[0m     )\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext/plain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m rheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mServiceUnavailableError\u001b[0m: The server is overloaded or not ready yet."
     ]
    }
   ],
   "source": [
    "# Add a user message\n",
    "paper_conversation.add_message(\"user\", \"Hi, how does PPO reinforcement learning work?\")\n",
    "chat_response = chat_completion_with_function_execution(\n",
    "    paper_conversation.conversation_history, functions=arxiv_functions\n",
    ")\n",
    "assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "paper_conversation.add_message(\"assistant\", assistant_message)\n",
    "display(Markdown(assistant_message))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ca3e18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function generation requested, calling function\n",
      "Finding and reading paper\n",
      "Chunking text from paper\n",
      "Summarizing each chunk of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4/4 [00:10<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing into overall summary\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "핵심 주장:\n",
       "- 이 논문은 시퀀스 생성 작업에서 Proximal Policy Optimization (PPO)의 사용에 대해 논의한다.\n",
       "- PPO-dynamic이라는 동적 접근법을 제안하고, 이를 합성 실험과 chit-chat 챗봇 작업에서의 효과를 보여준다.\n",
       "- 결과는 PPO와 PPO-dynamic이 안정성과 성능 측면에서 policy gradient보다 우수함을 보여준다.\n",
       "\n",
       "증거:\n",
       "- PPO-dynamic은 합성 계수 작업에서 REINFORCE와 MIXER와 비교했을 때 높은 정확도 점수를 달성한다.\n",
       "- PPO-dynamic의 학습 곡선은 PPO보다 빠른 진전을 보인다.\n",
       "- chit-chat 챗봇 작업에서 PPO-dynamic은 REINFORCE와 PPO보다 약간 높은 BLEU-2 점수를 달성한다.\n",
       "- PPO와 PPO-dynamic의 학습 곡선은 policy gradient보다 안정적이며, PPO-dynamic은 더 빠르게 수렴한다.\n",
       "\n",
       "결론:\n",
       "- PPO는 시퀀스 학습에 있어서 policy gradient보다 더 나은 최적화 방법이다.\n",
       "- PPO-dynamic은 하이퍼파라미터를 동적으로 조정하여 최적화 과정을 개선한다.\n",
       "- PPO는 GAN 기반 시퀀스 학습을 위한 새로운 최적화 방법으로 사용될 수 있다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add another user message to induce our system to use the second tool\n",
    "paper_conversation.add_message(\n",
    "    \"user\",\n",
    "    \"Can you read the PPO sequence generation paper for me and give me a summary\",\n",
    ")\n",
    "updated_response = chat_completion_with_function_execution(\n",
    "    paper_conversation.conversation_history, functions=arxiv_functions\n",
    ")\n",
    "display(Markdown(updated_response[\"choices\"][0][\"message\"][\"content\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91d653f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are arXivGPT, a helpful assistant pulls academic papers to answer user questions.\\nYou summarize the papers clearly so the customer can decide which to read to answer their question.\\nYou always provide the article_url and title so the user can understand the name of the paper and click through to access it.\\nBegin!'},\n",
       " {'role': 'user', 'content': 'Hi, how does PPO reinforcement learning work?'},\n",
       " {'role': 'user',\n",
       "  'content': 'Can you read the PPO sequence generation paper for me and give me a summary'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_conversation.conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44682ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a system message\n",
    "paper_system_message = \"\"\"You are arXivGPT, a helpful assistant pulls academic papers to answer user questions.\n",
    "You summarize the papers clearly so the customer can decide which to read to answer their question.\n",
    "You always provide the article_url and title so the user can understand the name of the paper and click through to access it.\n",
    "Begin!\"\"\"\n",
    "paper_conversation = Conversation()\n",
    "paper_conversation.add_message(\"system\", paper_system_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9fac412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are arXivGPT, a helpful assistant pulls academic papers to answer user questions.\\nYou summarize the papers clearly so the customer can decide which to read to answer their question.\\nYou always provide the article_url and title so the user can understand the name of the paper and click through to access it.\\nBegin!'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_conversation.conversation_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eae92f",
   "metadata": {},
   "source": [
    "## transformer 논문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7b8b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a system message\n",
    "paper_system_message = \"\"\"You are arXivGPT, a helpful assistant pulls academic papers to answer user questions.\n",
    "You summarize the papers clearly so the customer can decide which to read to answer their question.\n",
    "You always provide the article_url and title so the user can understand the name of the paper and click through to access it.\n",
    "Begin!\"\"\"\n",
    "paper_conversation = Conversation()\n",
    "paper_conversation.add_message(\"system\", paper_system_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93aa653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are arXivGPT, a helpful assistant pulls academic papers to answer user questions.\\nYou summarize the papers clearly so the customer can decide which to read to answer their question.\\nYou always provide the article_url and title so the user can understand the name of the paper and click through to access it.\\nBegin!'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_conversation.conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68c7fec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function generation requested, calling function\n",
      "Finding and reading paper\n",
      "Chunking text from paper\n",
      "Summarizing each chunk of text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing into overall summary\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Toolformer is a language model that can teach itself to use external tools via simple APIs. It overcomes the limitations of current language models by accessing up-to-date information and performing precise calculations. The model is trained in a self-supervised way, incorporating a range of tools such as a calculator, Q&A system, search engine, translation system, and calendar. The key steps of the approach involve sampling, executing, and filtering API calls, and merging them into the LM dataset. Toolformer achieves improved zero-shot performance on various tasks without sacrificing its core language modeling abilities. The paper also discusses the tools used in experiments and evaluates the model's performance in zero-shot settings."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a user message\n",
    "paper_conversation.add_message(\"user\", \"Hi, how does Transformer work?\")\n",
    "chat_response = chat_completion_with_function_execution(\n",
    "    paper_conversation.conversation_history, functions=arxiv_functions\n",
    ")\n",
    "assistant_message = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "paper_conversation.add_message(\"assistant\", assistant_message)\n",
    "display(Markdown(assistant_message))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e2b43f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
